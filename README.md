# Lensless Imaging with UNet Variants

For a more detailed explanation, see the bachelor thesis:[[TODO:add link](TODO)] 

## Introduction
Lensless imaging is an emerging technology that directly records light‚Äôs diffraction patterns without traditional lenses. Algorithms are then used to reconstruct the original image from these patterns. This approach presents a compelling alternative to traditional microscopy, addressing
trade-offs between resolution, field of view, and depth of view. However, its reliance on computationally intensive phase retrieval methods poses significant challenges. This thesis investigates the application of three deep learning models UNet, DRUNet, and SCUNet for phase retrieval and image reconstruction [[1](#1)][[2](#2)][[3](#3)]. Unlike traditional methods, these models can rapidly reconstruct various diffraction patterns and offer enhanced adaptability for complex imaging tasks.

## Methods
UNet has proven effective in lensless imaging [[4](#4)], particularly for segmentation and reconstruction tasks. This study compares UNet with two advanced models, DRUNet and SCUNet, to assess the impact of recent denoising techniques on lensless imaging performance.
### UNET
- Widely applied for segmentation and image reconstruction tasks
- Features a simple, yet effective architecture that generalizes well across diverse input types  
- Demonstrates robustness to noise and variations in lensless imaging data, making it a reliable baseline model

### DRUNET
- Originally designed for denoising
- Employs residual blocks to learn residual functions, improving efficiency and training dynamics
- Particularly effective in preserving critical information in low-resolution lensless images, enhancing feature representation

### SCUNET
- Hybrid neural network architecture combining convolutional and transformer-based approaches
- Leverages local modeling ability of residual convolutional layers
- Utilizes non-local modeling ability of swin transformer 
- Theoretically superior at capturing complex diffraction patterns

## Lensless imaging


The complex wavefront generated by object diffraction can be expressed as a product of amplitude and phase components:



$$
u_0 = A \cdot e^{i \cdot \phi}  \tag{1}
$$
Where $A$ represents the amplitude distribution and $\phi$ denotes the phase distribution. The fundamental phase retrieval problem involves reconstructing the phase $\phi$ from measurements of the intensity distribution $I$ at the sensor plane:

$$
I = |P_d(u_0)|^2  \tag{2}
$$
where $ùë¢_0$ represents the complex-valued wavefront matrix immediately after the object plane. The free-space propagation operator $ùëÉ_ùëë$   models the angular spectrum of light propagation over distance $ùëë$. For a more detailed examination, refer to [[5](#5)].

### Wavefront reconstruction pipeline.

![reconstruction pipeline](./figures/reconstruction%20pipeline.png)

## Experiments

The dataset used is part of Broad Bioimage Benchmark Collection (BBBC). It is composed of U2OS cancer cells and are particularly useful in cancer research. To prepare the dataset for phase retrieval, the configuration described in [[6](#6)] was used. The cell models used in the dataset represent realistic biological structure, with diameters ranging from **10 Œºm to 25 Œºm**. The simulated dataset contains **60000 samples**, with an 80/10/10 split reserved for training, validation, and testing.


### Results

#### Table 1, Quality metrics for simulated data

| Model             | SSIM  | RRMSE | PSNR  | Training time (min/epoch) | Params (M) | Inference time (s/i) |
|-------------------|-------|-------|-------|------------------------|------------|-----------------|
| Unet (depth 5)    | 0.9969| 5.35  | 43.22 | 10.43                 | 31.03      | 0.00131         |
| Unet (depth 4)    | 0.9967| 5.45  | 43.07 | 9.08                  | 7.69       | 0.00115         |
| DRUNet (depth 4)  | 0.9989| 3.11  | 48.18 | 28.85                 | 32.63      | 0.00305         |
| DRUNet (depth 3)  | 0.9991| 2.69  | 49.63 | 16.01                 | 7.99       | 0.00157         |
| SCUNet (depth 4)  | 0.9985| 3.11  | 48.15 | 80.87                 | 17.94      | 0.03453         |
| SCUNet (depth 3)  | 0.9984| 3.28  | 47.53 | 56.58                 | 4.40       | 0.02306         |
#### Visual comparison
![results](./figures/quantative%20results.png)
Each row represents a different example, with columns showing the corresponding Amplitude, Phase, and Predicted outputs from the lightweight variants of UNet, DRUNet, and SCUNet from Table 1 along with their SSIM and PSNR values (SSIM/PSNR).
## References

<a id="1">[1]</a> Ronneberger, O., Fischer, P. and Brox, T. U-net: Convolutional networks for biomedical image segmentation. Medical image computing and computer-assisted intervention-MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18. Springer. 2015.

<a id="2">[2]</a> Zhang, K., Li, Y., Zuo, W., Zhang, L., Van Gool, L. and Timofte, R Plug-and-play image restoration with deep denoiser prior. IEEE Transactions on Pattern Analysis and Machine Intelligence 44.10 (2021).

<a id="3">[3]</a> Zhang, K., Li, Y., Liang, J., Cao, J., Zhang, Y., Tang, H., Fan, D-P., Timofte, R. and Gool, L. V. Practical blind image denoising via Swin-Conv-UNet and data synthesis. Machine Intelligence Research 20.6 (2023).

<a id="4">[4]</a> Sinha, A., Lee, J., Li, S. and Barbastathis, G. Lensless computational imaging through deep learning. Optica 4.9 (2017).

<a id="5">[5]</a>	Goodman, J. W. Introduction to Fourier optics. Roberts and Company publishers, 2005.

<a id="6">[6]</a> Shevkunov, I., Kandhavelu, M. and Egiazarian, K. A deep learning-based concept for quantitative phase imaging upgrade of bright-field microscope. Applied Physics Letters 124.4 (2024).
